{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c77d3b9a-82da-445a-8fd6-a26a5830b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "# import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "import pickle\n",
    "from helpers import makedir\n",
    "import protopnet\n",
    "import push\n",
    "import prune\n",
    "import train_and_test as tnt\n",
    "import save\n",
    "from log import create_logger\n",
    "from preprocess import mean, std, preprocess_input_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fac6191c-ea89-4da3-8060-25ca3f5a5c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparser = argparse.ArgumentParser()\\nparser.add_argument('-gpuid', nargs=1, type=str, default='0') # python3 main.py -gpuid=0,1,2,3\\nargs = parser.parse_args()\\nos.environ['CUDA_VISIBLE_DEVICES'] = args.gpuid[0]\\nprint(os.environ['CUDA_VISIBLE_DEVICES'])\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ORIGINAL WORK FOR REFERENCE\n",
    "\"\"\"\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-gpuid', nargs=1, type=str, default='0') # python3 main.py -gpuid=0,1,2,3\n",
    "args = parser.parse_args()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpuid[0]\n",
    "print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1106d9e-e810-4d22-93f7-57aa42aa88c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom settings import base_architecture, img_size, prototype_shape, num_classes,                      prototype_activation_function, add_on_layers_type, experiment_run\\n\\nbase_architecture_type = re.match('^[a-z]*', base_architecture).group(0)\\n\\nmodel_dir = './saved_models/' + base_architecture + '/' + experiment_run + '/'\\nmakedir(model_dir)\\nshutil.copy(src=os.path.join(os.getcwd(), __file__), dst=model_dir)\\nshutil.copy(src=os.path.join(os.getcwd(), 'settings.py'), dst=model_dir)\\nshutil.copy(src=os.path.join(os.getcwd(), base_architecture_type + '_features.py'), dst=model_dir)\\nshutil.copy(src=os.path.join(os.getcwd(), 'model.py'), dst=model_dir)\\nshutil.copy(src=os.path.join(os.getcwd(), 'train_and_test.py'), dst=model_dir)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ORIGINAL WORK, SAVING DATA\n",
    "\"\"\"\n",
    "from settings import base_architecture, img_size, prototype_shape, num_classes, \\\n",
    "                     prototype_activation_function, add_on_layers_type, experiment_run\n",
    "\n",
    "base_architecture_type = re.match('^[a-z]*', base_architecture).group(0)\n",
    "\n",
    "model_dir = './saved_models/' + base_architecture + '/' + experiment_run + '/'\n",
    "makedir(model_dir)\n",
    "shutil.copy(src=os.path.join(os.getcwd(), __file__), dst=model_dir)\n",
    "shutil.copy(src=os.path.join(os.getcwd(), 'settings.py'), dst=model_dir)\n",
    "shutil.copy(src=os.path.join(os.getcwd(), base_architecture_type + '_features.py'), dst=model_dir)\n",
    "shutil.copy(src=os.path.join(os.getcwd(), 'model.py'), dst=model_dir)\n",
    "shutil.copy(src=os.path.join(os.getcwd(), 'train_and_test.py'), dst=model_dir)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d2536-339a-4650-88e1-d1fc3e61d3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff8911f6-050e-45e9-a2a5-12096ec7697d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nexperiment_run = '003'\\ndata_path = './datasets/cub200_cropped/'\\ntrain_dir = data_path + 'train_cropped_augmented/'\\ntest_dir = data_path + 'test_cropped/'\\ntrain_push_dir = data_path + 'train_cropped/'\\n\\ntrain_batch_size = 80\\ntest_batch_size = 100\\ntrain_push_batch_size = 75\\n\\nnormalize = transforms.Normalize(mean=mean,\\n                                 std=std)\\n\\n# all datasets\\n# train set\\ntrain_dataset = datasets.ImageFolder(\\n    train_dir,\\n    transforms.Compose([\\n        transforms.Resize(size=(img_size, img_size)),\\n        transforms.ToTensor(),\\n        normalize,\\n    ]))\\ntrain_loader = torch.utils.data.DataLoader(\\n    train_dataset, batch_size=train_batch_size, shuffle=True,\\n    num_workers=4, pin_memory=False)\\n# push set\\ntrain_push_dataset = datasets.ImageFolder(\\n    train_push_dir,\\n    transforms.Compose([\\n        transforms.Resize(size=(img_size, img_size)),\\n        transforms.ToTensor(),\\n    ]))\\n\\ntrain_push_loader = torch.utils.data.DataLoader(\\n    train_push_dataset, batch_size=train_push_batch_size, shuffle=False,\\n    num_workers=4, pin_memory=False)\\n\\n# test set\\ntest_dataset = datasets.ImageFolder(\\n    test_dir,\\n    transforms.Compose([\\n        transforms.Resize(size=(img_size, img_size)),\\n        transforms.ToTensor(),\\n        normalize,\\n    ]))\\ntest_loader = torch.utils.data.DataLoader(\\n    test_dataset, batch_size=test_batch_size, shuffle=False,\\n    num_workers=4, pin_memory=False)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ORIGINAL WORK, ONLY FOR REFERENCE\n",
    "# load the data\n",
    "\"\"\"\n",
    "experiment_run = '003'\n",
    "data_path = './datasets/cub200_cropped/'\n",
    "train_dir = data_path + 'train_cropped_augmented/'\n",
    "test_dir = data_path + 'test_cropped/'\n",
    "train_push_dir = data_path + 'train_cropped/'\n",
    "\n",
    "train_batch_size = 80\n",
    "test_batch_size = 100\n",
    "train_push_batch_size = 75\n",
    "\n",
    "normalize = transforms.Normalize(mean=mean,\n",
    "                                 std=std)\n",
    "\n",
    "# all datasets\n",
    "# train set\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    train_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, shuffle=True,\n",
    "    num_workers=4, pin_memory=False)\n",
    "# push set\n",
    "train_push_dataset = datasets.ImageFolder(\n",
    "    train_push_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ]))\n",
    "\n",
    "train_push_loader = torch.utils.data.DataLoader(\n",
    "    train_push_dataset, batch_size=train_push_batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=False)\n",
    "\n",
    "# test set\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    test_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a781d579-140d-4038-8a63-9f97cbb260af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OURS\n",
    "\n",
    "# SETTINGS FILE\n",
    "\n",
    "# our default architecture\n",
    "# it is used in ppnet class to download pretrained resnet34\n",
    "base_architecture = 'resnet34'\n",
    "img_size = 224\n",
    "\n",
    "# 4 prototypes per 1 class, 20 classes == 80 prototypes\n",
    "prototype_shape = (80, 128, 1, 1)\n",
    "num_classes = 20\n",
    "prototype_activation_function = 'log'\n",
    "add_on_layers_type = 'regular'\n",
    "\n",
    "train_batch_size = 80\n",
    "test_batch_size = 100\n",
    "train_push_batch_size = 75\n",
    "\n",
    "\n",
    "\n",
    "from dataset.CombinedDataLoader import CDL\n",
    "root = './dataset/data'\n",
    "\n",
    "normalize = transforms.Normalize(mean=mean,\n",
    "                                 std=std)\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize # very important\n",
    "])\n",
    "\n",
    "trans_push = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # don't normalize push loader!\n",
    "])\n",
    "\n",
    "\n",
    "ds_train = CDL(root, train=True, transform=trans, num_classes=num_classes, images=['cropped', \"rotated\", \"sheared\", \"skewed\"])\n",
    "ds_train_push = CDL(root, train=True, transform=trans_push, num_classes=num_classes, images=['cropped', \"rotated\", \"sheared\", \"skewed\"])\n",
    "ds_test = CDL(root, train=False, transform=trans, num_classes=num_classes, images=['cropped'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5edb18e6-8ed8-48de-af59-7381d0767042",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_push_loader = torch.utils.data.DataLoader(ds_train_push, batch_size=train_push_batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(ds_train, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(ds_test, batch_size=test_batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f88667d-ebb7-43cc-8d8a-69545910d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "model_dir = f\"ProtoPNet_base_arch_{base_architecture}_n_classes_{num_classes}_prot_shape_{prototype_shape}_{dt_string}\"\n",
    "makedir(model_dir)\n",
    "\n",
    "log, logclose = create_logger(log_filename=os.path.join(model_dir, 'train.log'))\n",
    "img_dir = os.path.join(model_dir, 'img')\n",
    "makedir(img_dir)\n",
    "weight_matrix_filename = 'outputL_weights'\n",
    "prototype_img_filename_prefix = 'prototype-img'\n",
    "prototype_self_act_filename_prefix = 'prototype-self-act'\n",
    "proto_bound_boxes_filename_prefix = 'bb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9994b92c-9099-4186-b3e0-c979fc58afd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 2400\n",
      "push set size: 2400\n",
      "test set size: 515\n",
      "train batch size: 80\n"
     ]
    }
   ],
   "source": [
    "log('training set size: {0}'.format(len(train_loader.dataset)))\n",
    "log('push set size: {0}'.format(len(train_push_loader.dataset)))\n",
    "log('test set size: {0}'.format(len(test_loader.dataset)))\n",
    "log('train batch size: {0}'.format(train_batch_size))\n",
    "\n",
    "# print(len(train_loader.dataset))\n",
    "# print(len(train_push_loader.dataset))\n",
    "# print(len(test_loader.dataset))\n",
    "# print(train_batch_size)\n",
    "\n",
    "# construct the model\n",
    "ppnet = protopnet.construct_PPNet(base_architecture=base_architecture,\n",
    "                              pretrained=True, img_size=img_size,\n",
    "                              prototype_shape=prototype_shape,\n",
    "                              num_classes=num_classes,\n",
    "                              prototype_activation_function=prototype_activation_function,\n",
    "                              add_on_layers_type=add_on_layers_type)\n",
    "\n",
    "ppnet = ppnet.cuda()\n",
    "ppnet_multi = torch.nn.DataParallel(ppnet)\n",
    "class_specific = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d5782e7-bf3f-4ed1-8ed0-c8d69aa78da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "\n",
    "joint_optimizer_lrs = {'features': 1e-4,\n",
    "                       'add_on_layers': 3e-3,\n",
    "                       'prototype_vectors': 3e-3}\n",
    "joint_lr_step_size = 5\n",
    "\n",
    "warm_optimizer_lrs = {'add_on_layers': 3e-3,\n",
    "                      'prototype_vectors': 3e-3}\n",
    "\n",
    "last_layer_optimizer_lr = 1e-4\n",
    "\n",
    "coefs = {\n",
    "    'crs_ent': 1,\n",
    "    'clst': 0.8,\n",
    "    'sep': -0.08,\n",
    "    'l1': 1e-4,\n",
    "}\n",
    "\n",
    "joint_optimizer_specs = \\\n",
    "[{'params': ppnet.features.parameters(), 'lr': joint_optimizer_lrs['features'], 'weight_decay': 1e-3}, # bias are now also being regularized\n",
    " {'params': ppnet.add_on_layers.parameters(), 'lr': joint_optimizer_lrs['add_on_layers'], 'weight_decay': 1e-3},\n",
    " {'params': ppnet.prototype_vectors, 'lr': joint_optimizer_lrs['prototype_vectors']},\n",
    "]\n",
    "joint_optimizer = torch.optim.Adam(joint_optimizer_specs)\n",
    "joint_lr_scheduler = torch.optim.lr_scheduler.StepLR(joint_optimizer, step_size=joint_lr_step_size, gamma=0.1)\n",
    "\n",
    "\n",
    "warm_optimizer_specs = \\\n",
    "[{'params': ppnet.add_on_layers.parameters(), 'lr': warm_optimizer_lrs['add_on_layers'], 'weight_decay': 1e-3},\n",
    " {'params': ppnet.prototype_vectors, 'lr': warm_optimizer_lrs['prototype_vectors']},\n",
    "]\n",
    "warm_optimizer = torch.optim.Adam(warm_optimizer_specs)\n",
    "\n",
    "\n",
    "last_layer_optimizer_specs = [{'params': ppnet.last_layer.parameters(), 'lr': last_layer_optimizer_lr}]\n",
    "last_layer_optimizer = torch.optim.Adam(last_layer_optimizer_specs)\n",
    "\n",
    "# weighting of different training losses\n",
    "\n",
    "\n",
    "\n",
    "# number of training epochs, number of warm epochs, push start epoch, push epochs\n",
    "num_train_epochs = 500\n",
    "num_warm_epochs = 5\n",
    "push_start = 10\n",
    "push_epochs = [i for i in range(num_train_epochs) if i % 10 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9be24ac0-4298-4a6c-9423-9b4053ca2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir=None, model_name=None, ppnet=None, joint_optimizer=None, warm_optimizer=None, last_layer_optimizer=None):\n",
    "    # none everywhere as to not load anything that jupyter holds in memory\n",
    "    model_path = model_dir + '/' + model_name\n",
    "    joint_optimizer_path = model_dir + '/joint_optimizer.pth'\n",
    "    warm_optimizer_path = model_dir + '/warm_optimizer.pth'\n",
    "    last_layer_optimizer_path = model_dir + '/last_layer_optimizer.pth'\n",
    "    variables_path = model_dir + '/variables.pkl'\n",
    "\n",
    "\n",
    "    # WARNING: THEY SAVE WHOLE MODEL, I SAVE DICT STATE\n",
    "    ppnet.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    # Load the optimizer states\n",
    "    joint_optimizer.load_state_dict(torch.load(joint_optimizer_path))\n",
    "    warm_optimizer.load_state_dict(torch.load(warm_optimizer_path))\n",
    "    last_layer_optimizer.load_state_dict(torch.load(last_layer_optimizer_path))\n",
    "    \n",
    "    # It probably isn't that useful, so they are not returned\n",
    "    with open(variables_path, 'rb') as f:\n",
    "        variables = pickle.load(f)\n",
    "    coefs = variables['coefs']\n",
    "    num_train_epochs = variables['num_train_epochs']\n",
    "    num_warm_epochs = variables['num_warm_epochs']\n",
    "    push_start = variables['push_start']\n",
    "    push_epochs = variables['push_epochs']\n",
    "    class_specific = variables['class_specific']\n",
    "\n",
    "\n",
    "    \n",
    "    # Load other variables as needed\n",
    "    log(f\"Model and optimizers loaded from {model_dir}\")\n",
    "    log(f\"Model: {model_path}\")\n",
    "    log(f\"Joint optimizer: {joint_optimizer_path}\")\n",
    "    log(f\"Warm optimizer: {warm_optimizer_path}\")\n",
    "    log(f\"Last layer_optimizer: {last_layer_optimizer_path}\")\n",
    "    # log(f\"Variables: {variables_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2502a86d-e6a5-42fc-a9a2-66505695518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and optimizers loaded from logdir_4_parts_0\n",
      "Model: logdir_4_parts_0/logdir_4_parts_0_0.8058252427184466.pth\n",
      "Joint optimizer: logdir_4_parts_0/joint_optimizer.pth\n",
      "Warm optimizer: logdir_4_parts_0/warm_optimizer.pth\n",
      "Last layer_optimizer: logdir_4_parts_0/last_layer_optimizer.pth\n"
     ]
    }
   ],
   "source": [
    "load_model_dir = 'ProtoPNet_base_arch_resnet34_n_classes_20_prot_shape_(80, 128, 1, 1)_28_05_2023_15_15_19'\n",
    "load_model_name = 'ProtoPNet_base_arch_resnet34_n_classes_20_prot_shape_(80, 128, 1, 1)_28_05_2023_15_15_19_0.8019417475728156.pth'\n",
    "load_model(model_dir=load_model_dir, model_name=load_model_name, ppnet=ppnet, joint_optimizer=joint_optimizer, warm_optimizer=warm_optimizer, last_layer_optimizer=last_layer_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea030f3-18ae-404c-b80f-49675d85eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "target_acc = 0.80\n",
    "log('start training')\n",
    "import copy\n",
    "for epoch in range(num_train_epochs):\n",
    "    log('epoch: \\t{0}'.format(epoch))\n",
    "\n",
    "    if epoch < num_warm_epochs:\n",
    "        tnt.warm_only(model=ppnet_multi, log=log)\n",
    "        _ = tnt.train(model=ppnet_multi, dataloader=train_loader, optimizer=warm_optimizer,\n",
    "                      class_specific=class_specific, coefs=coefs, log=log)\n",
    "    else:\n",
    "        tnt.joint(model=ppnet_multi, log=log)\n",
    "        joint_lr_scheduler.step()\n",
    "        _ = tnt.train(model=ppnet_multi, dataloader=train_loader, optimizer=joint_optimizer,\n",
    "                      class_specific=class_specific, coefs=coefs, log=log)\n",
    "\n",
    "    accu = tnt.test(model=ppnet_multi, dataloader=test_loader,\n",
    "                    class_specific=class_specific, log=log)\n",
    "    save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + 'nopush', accu=accu,\n",
    "                                target_accu=target_acc, log=log)\n",
    "\n",
    "    if epoch >= push_start and epoch in push_epochs:\n",
    "        push.push_prototypes(\n",
    "            train_push_loader, # pytorch dataloader (must be unnormalized in [0,1])\n",
    "            prototype_network_parallel=ppnet_multi, # pytorch network with prototype_vectors\n",
    "            class_specific=class_specific,\n",
    "            preprocess_input_function=preprocess_input_function, # normalize if needed\n",
    "            prototype_layer_stride=1,\n",
    "            root_dir_for_saving_prototypes=img_dir, # if not None, prototypes will be saved here\n",
    "            epoch_number=epoch, # if not provided, prototypes saved previously will be overwritten\n",
    "            prototype_img_filename_prefix=prototype_img_filename_prefix,\n",
    "            prototype_self_act_filename_prefix=prototype_self_act_filename_prefix,\n",
    "            proto_bound_boxes_filename_prefix=proto_bound_boxes_filename_prefix,\n",
    "            save_prototype_class_identity=True,\n",
    "            log=log)\n",
    "        accu = tnt.test(model=ppnet_multi, dataloader=test_loader,\n",
    "                        class_specific=class_specific, log=log)\n",
    "        save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + 'push', accu=accu,\n",
    "                                    target_accu=target_acc, log=log)\n",
    "\n",
    "        if prototype_activation_function != 'linear':\n",
    "            tnt.last_only(model=ppnet_multi, log=log)\n",
    "            for i in range(20):\n",
    "                log('iteration: \\t{0}'.format(i))\n",
    "                _ = tnt.train(model=ppnet_multi, dataloader=train_loader, optimizer=last_layer_optimizer,\n",
    "                              class_specific=class_specific, coefs=coefs, log=log)\n",
    "                accu = tnt.test(model=ppnet_multi, dataloader=test_loader,\n",
    "                                class_specific=class_specific, log=log)\n",
    "                save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + '_' + str(i) + 'push', accu=accu,\n",
    "                                            target_accu=target_acc, log=log)\n",
    "   \n",
    "logclose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ce38468-18a0-4ee5-a062-92de61e5f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING MODEL TO TRAIN LATER\n",
    "\n",
    "# Save the model state\n",
    "model_path = model_dir + '/' + model_dir + '_' + str(accu) + '.pth'\n",
    "torch.save(ppnet.state_dict(), model_path)\n",
    "\n",
    "# Save the optimizer states\n",
    "joint_optimizer_path = model_dir + '/joint_optimizer.pth'\n",
    "torch.save(joint_optimizer.state_dict(), joint_optimizer_path)\n",
    "\n",
    "warm_optimizer_path = model_dir + '/warm_optimizer.pth'\n",
    "torch.save(warm_optimizer.state_dict(), warm_optimizer_path)\n",
    "\n",
    "last_layer_optimizer_path = model_dir + '/last_layer_optimizer.pth'\n",
    "torch.save(last_layer_optimizer.state_dict(), last_layer_optimizer_path)\n",
    "\n",
    "# Save other variables\n",
    "variables_path = model_dir + '/variables.pkl'\n",
    "variables = {\n",
    "    'coefs': coefs,\n",
    "    'num_train_epochs': num_train_epochs,\n",
    "    'num_warm_epochs': num_warm_epochs,\n",
    "    'push_start': push_start,\n",
    "    'push_epochs': push_epochs,\n",
    "    'class_specific': class_specific,\n",
    "    # Include other variables you want to save\n",
    "}\n",
    "with open(variables_path, 'wb') as f:\n",
    "    pickle.dump(variables, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fffafb-11a9-4339-b5a5-a83dc97b9d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
